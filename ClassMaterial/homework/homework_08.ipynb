{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "editable": false,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "---\n",
    "execute: \n",
    "  cache: false\n",
    "format: \n",
    "  pdf:\n",
    "    include-in-header: \n",
    "       text: |\n",
    "         \\newcommand{\\textasciicaret}{\\^{}}\n",
    "         \\usepackage{fvextra}\n",
    "         \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n",
    "    include-before-body:\n",
    "        text: |\n",
    "         \\RecustomVerbatimEnvironment{verbatim}{Verbatim}{showspaces = false, showtabs = false, breaksymbolleft={}, breaklines}\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Hypothesis tests\n",
    "\n",
    "Welcome to the eighth homework! \n",
    "\n",
    "In this homework you practice running hypothesis tests.\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. \n",
    "\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is due **Sunday November 10th at 11pm.** You can turn in the assignment up to 24 hours late for 90% credit (after that, the homework will only be accepted with a dean's excuse). \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas.  You can also post questions or start discussions on Ed Discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In order to complete the homework, it is necessary to download a few files. Please run the code below **only once** to download data needed to complete the homework. To run the code, click in the cell below and press the play button (or press shift-enter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running this notebook in colabs, please uncomment and run the following two lines\n",
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file `college_scorecard_subset_2021_2022.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n",
      "The file `CCBASIC_categories.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n"
     ]
    }
   ],
   "source": [
    "# Please run this code once to download the files you will need to complete the homework \n",
    "\n",
    "import YData \n",
    "\n",
    "# Downlooad college scorecard data and map files\n",
    "YData.download.download_data(\"college_scorecard_subset_2021_2022.csv\")\n",
    "YData.download.download_data(\"CCBASIC_categories.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quote and reaction\n",
    "\n",
    "There is no quote and reaction for this week. Please use the extra time to work on your project! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports functions from packages we will use below.\n",
    "# Please run it each time you load the Jupyter notebook\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hypothesis test on a single proportion: Is it possible to smell whether someone has Parkinson’s disease? \n",
    "\n",
    "Joy Milne was a Scottish woman who claimed to have the ability to smell whether someone had Parkinson’s disease. To test this claim, researchers at University of Edinburgh gave Joy 6 shirts that had been worn by people who had Parkinson’s disease and 6 people who did not. Joy identified 11 out of the 12 shirts correctly. \n",
    "\n",
    "Let's run a hypothesis test to assess whether these results provide convincing evidence that Joy can really smell whether someone has Parkinson’s disease. \n",
    "\n",
    "For the purpose of this question, you can assume that when Joy's abilities are tested, she is always tested in a similar setup as the test run by University of Edinburgh, where 50% of shirts she has to smell are from people with Parkinson’s disease (and you can also assume she does not know that exactly 50% of the shirts come from people with Parkinson’s disease, so she will also take her best guess based on smelling each shirt individually). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1 (4 points)**: Please write down the 5 steps for running a hypothesis test. We will use these steps to run an actual hypothesis test in the rest of the problem, but let’s just start by writing down what the steps are. You can look at the lecture slides if you need to, although you should memorize these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "1.  \n",
    "2.  \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2 (5 points)**: Now let's start on the hypothesis test by stating the null and alternative hypotheses both using words and as an equation/inequality using the appropriate symbols we discussed in class. I.e., you should have four statements: 2 statements for stating the hypotheses in words, and 2 statments for stating them using symbols. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "*In words:*\n",
    "\n",
    "Null hypothesis: \n",
    "\n",
    "Alternative hypothesis: \n",
    "\n",
    "*In symbols:*\n",
    "\n",
    "$H_0:$\n",
    "\n",
    "$H_A:$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3 (5 points)**: Now please do step 2 of hypothesis testing by computing the statistic of interest and save it in the variable `joy_stat`. In the answer section, please write down the symbol we should use to denote the observed statistic based on the symbols we discussed in class. Also, write down whether you think the value of this observed statistic is likely to be obtained if Joy was guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4 (5 points)**: Let's now do step 3 of hypothesis testing. To start, please write a function `generate_proportion(n, heads_probability)` that simulates a proportion of \"heads\" one might get from flipping *n* coins. Each coin should have a probaility `heads_probability` of getting a \"head\" on each coin flip (assuming each coin flip is independent).\n",
    "\n",
    "Once you have written the `generate_proportion(n, heads_probability)` function, use this function to simulate one example of the proportion of shirts Joy would correctly identify if she were purely guessing (assuming a 50% chance of guessing each shirt correctly).\n",
    "\n",
    "Hint: Looking at the class 18 code might help, but please make sure you are understanding the code you write below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the generate_proportion() function \n",
    "def generate_proportion(n, heads_probability):\n",
    "    ...\n",
    "\n",
    "\n",
    "# use the generate_proportion() function to simulate one example of the proportion of correct preditions Paul might make if he was merely guessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5 (5 points)**: Now use for loop and the `generate_proportion()` function to generate a null distribution that would occur if Joy was guessing. Your null distribution should be a list that has 10,000 simulated proportions in it. Save the values in this null distribution to a variable called `null_dist`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a null distribution \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6 (5 points)**: Next plot the null distribution as a histogram, set the `bins` argument to 50 so that your histogram has bins. Also add a red circle at the observed statistic value. Based on looking at this plot, what would you estimate the p-value to be? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution and the observed statistic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7 (5 points)**: Next do step 4 of hypothesis testing by calculating the p-value and print out the value you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the p-value \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8 (5 points)**: Finally, do step 5 of hypothesis testing and make a judgment call as to whether you believe Joy can really smell whether has Parkinson’s disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis test on mean SAT scores between different types of colleges\n",
    "\n",
    "As you will recall from homework 6, the college scorecard contains data on higher education institutions in the United States. \n",
    "\n",
    "As you will also hopefully recall from creating interactive visualizations of SAT scores on question 1.5 from homework 6, colleges that had the highest SAT scores had Carnegie classifications of \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21). \n",
    "\n",
    "Let's now run a hypothesis test to test whether, on average, students' average SAT scores from \"Doctoral Universities: Very High Research Activity\" is higher than the average SAT scores for students who attend \"Baccalaureate Colleges: Arts & Sciences Focus\". \n",
    "\n",
    "The college scorecard data is loaded for you in the following cell, and a codebook for a few of the columns is below. \n",
    "\n",
    "\n",
    "#### Codebook\n",
    "\n",
    "1. `UNITID`: Unit ID for institution\n",
    "\n",
    "2. `INSTNM`: Institution name\n",
    "\n",
    "10. `CCBASIC`: Carnegie Classification; e.g., 15 = Doctoral Universities: Very High Research Activity\n",
    "\n",
    "11. `ADM_RATE`: Admission rate\n",
    "\n",
    "12. `SAT_AVG`: Average SAT equivalent score of students admitted\n",
    "\n",
    "18. `TUITFTE`: Net tuition revenue per full-time equivalent student\n",
    "\n",
    "36. `MD_EARN_WNE_MALE0_P10`: Median earnings of non-male students working and not enrolled 10 years after entry\n",
    "\n",
    "37. `MD_EARN_WNE_MALE1_P10`: Median earnings of male students working and not enrolled 10 years after entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>HIGHDEG</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CCBASIC</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>GRADS</th>\n",
       "      <th>BOOKSUPPLY</th>\n",
       "      <th>ROOMBOARD_ON</th>\n",
       "      <th>ENDOWBEGIN</th>\n",
       "      <th>ENDOWEND</th>\n",
       "      <th>GT_THRESHOLD_P10</th>\n",
       "      <th>MD_EARN_WNE_MALE0_P10</th>\n",
       "      <th>MD_EARN_WNE_MALE1_P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34.783368</td>\n",
       "      <td>-86.568502</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.6022</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>9240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>36050.0</td>\n",
       "      <td>36377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33.505697</td>\n",
       "      <td>-86.799345</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>8685.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>12307.0</td>\n",
       "      <td>537349307.0</td>\n",
       "      <td>539858544.0</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>42007.0</td>\n",
       "      <td>56164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100706</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>35899</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34.724557</td>\n",
       "      <td>-86.640449</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5891</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>10652.0</td>\n",
       "      <td>77250279.0</td>\n",
       "      <td>75837207.0</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>45170.0</td>\n",
       "      <td>66070.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID                               INSTNM        CITY STABBR         ZIP  \\\n",
       "0  100654             Alabama A & M University      Normal     AL       35762   \n",
       "1  100663  University of Alabama at Birmingham  Birmingham     AL  35294-0110   \n",
       "2  100706  University of Alabama in Huntsville  Huntsville     AL       35899   \n",
       "\n",
       "   HIGHDEG  CONTROL   LATITUDE  LONGITUDE  CCBASIC  ...  UGDS_MEN  UGDS_WOMEN  \\\n",
       "0        4        1  34.783368 -86.568502     18.0  ...    0.3978      0.6022   \n",
       "1        4        1  33.505697 -86.799345     15.0  ...    0.3816      0.6184   \n",
       "2        4        1  34.724557 -86.640449     16.0  ...    0.5891      0.4109   \n",
       "\n",
       "    GRADS  BOOKSUPPLY  ROOMBOARD_ON   ENDOWBEGIN     ENDOWEND  \\\n",
       "0   884.0      1600.0        9240.0          NaN          NaN   \n",
       "1  8685.0      1200.0       12307.0  537349307.0  539858544.0   \n",
       "2  1972.0      2200.0       10652.0   77250279.0   75837207.0   \n",
       "\n",
       "   GT_THRESHOLD_P10  MD_EARN_WNE_MALE0_P10  MD_EARN_WNE_MALE1_P10  \n",
       "0            0.6044                36050.0                36377.0  \n",
       "1            0.7472                42007.0                56164.0  \n",
       "2            0.7769                45170.0                66070.0  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorecard = pd.read_csv(\"college_scorecard_subset_2021_2022.csv\")\n",
    "\n",
    "scorecard.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 (4 points)**: As always, please start your hypothesis test with \"step 1\" by writing down the null and alternative hypotheses using words (i.e., a 1-2 sentence written description) and using the symbols we have discussed in class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "*In words:*\n",
    "\n",
    "Null hypothesis: \n",
    "\n",
    "Alternative hypothesis: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*In symbols:*\n",
    "\n",
    "$H_0:$\n",
    "\n",
    "$H_A:$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (4 points)**: Now let's start on step 2 of hypothesis testing by creating our statistic of interest and visualizing our data. To do this, we need to reduce our data to just the relevant data. Please create a name `scorecard2` which has only data from institutions that are classified as \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21). Also, to make our analyses easier, `scorecard2` should only have two columns which are `CCBASIC` and `SAT_AVG`. \n",
    "\n",
    "Once, you have created this DataFrame, print the first 5 rows, and the number of rows in the DataFrame, to show your work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (3 points)**: Now create a DataFrame called `mean_SAT` which has the mean SAT scores for \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and for \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21); i.e., there should be two rows corresponding to the two institution types and a single column called `SAT_AVG` which has the average scores for these two institution types averaged over all colleges of a particular type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4 (3 points)**: Now let's actually do step 2 by using the `mean_SAT` DataFrame you created above to create a name `obs_stat` which has the statistic of interest. For our hypothesis test here, our statistic of interest should be $\\bar{x}_{Doc} - \\bar{x}_{Bac}$; where $\\bar{x}_{Doc}$ is the average value of the SAT_AVG scores over all \"Doctoral Universities: Very High Research Activity\" institutions and $\\bar{x}_{Bac}$ is the SAT_AVG scores averaged over all \"Baccalaureate Colleges: Arts & Sciences Focus\" institutions. \n",
    "\n",
    "Print the value of `obs_stat` to show your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5 (4 points)**: Before we go on to step 3 of creating the null distribution, let's visualize the data. \n",
    "\n",
    "Please use seaborn to visualize the data in a way that gives insight into the question of interest. In particular, try to visualize the whole data set in `scorecard2` (rather than just looking at the mean statistics that you calculated above) in a way that gives meaningful insight. In the answer section, report, based on looking at the visualization you created, whether you believe there is a difference in the mean (average) SAT scores between these different type of schools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6 (4 points)**: Now, let's run step 3 of our hypothesis test by creating a null distribution. \n",
    "\n",
    "To do this, let's first write a function called `mean_diff(scorecard_data)` which takes a \"scorecard\" DataFrame that is the same as the `scorecard2` DataFrame above; i.e., the DataFrame should have a column called `CCBASIC` that has two levels corresponding to Carnegie classification levels 15 and 21, and a column called `SAT_AVG` that has the average SAT scores.\n",
    "\n",
    "From this `scorecard_data` DataFrame, the function should return the difference in means from schools with a `CCBASIC` of Carnegie classification levels 15 and 21.\n",
    "\n",
    "Test that your function works by running it on the `scorecard2` DataFrame and showing that it returns the same observed statistic value that you calculated in question 2.4.\n",
    "\n",
    "\n",
    "Hint: To write this function, simply use the code from questions 2.3 and 2.4 and wrap the code into a function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_diff(scorecard_data):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7 (4 points)**: Now let's create one point in our null distribution. \n",
    "\n",
    "To do this, please create a DataFrame called `scorecard_shuff` which is the same as the `scorecard2` DataFrame but the values in the `CCBASIC` column should be shuffled to be in random order. Once you have created this `scorecard_shuff` print the first 5 rows to show that you have done this correctly. \n",
    "\n",
    "Hint: To shuffle the values in the column, passing the `CCBASIC` Series values to the `np.random.permutation()` will be useful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8 (3 points)**: Now that you have a shuffled data frame, use it with the `mean_diff()` function to generate one statistic consistent with the null distribution. Show that this works by printing the shuffled statistic value below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9 (4 points)**: Now that we can create one statistic consistent with the null hypothesis, we can create a full null distribution by simply repeating this process 10,000 times.\n",
    "\n",
    "Starting with an empty list called `null_dist`, use a for loop to create a null distribution by appending randomly shuffled statistic values onto this list. Print the length of the list at the end of the cell to show the code worked.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dist = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10 (4 points)**: Let's now visualize the null distribution as a histogram. \n",
    "\n",
    "From looking at the null distribution, report in the answer section what you think the p-value will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11 (3 points)**: Now calculate the actual p-value (i.e., the proportion of statistics in the null distribution that are as large or larger than the observed statistic). Print out the p-value below to show your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.12 (3 points)**: Based on the p-value you calculated, what can you say about the null hypothesis? What does this lead you to conclude about the mean SAT scores for different types of colleges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reflection (3 points)\n",
    "\n",
    "Please reflect on how the homework went by going to Canvas, going to the Quizzes link, and clicking on reflection on homework 8. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_t-9kUXUpRf"
   },
   "source": [
    "## 4. Submission\n",
    "\n",
    "Once you're finished filling in and running all cells, you should submit your assignment as a pdf on Gradescope. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. When submitting on Gradescope, please **make sure to select the correct pages of your pdf that correspond to each problem**. Failure to mark pages correctly **will result in points being deducted** from your homework score.\n",
    "\n",
    "To convert this Jupyter notebook document to a pdf please run the code in the cell below, which will create pdf document that you can upload to Gradescope. \n",
    "\n",
    "Please be sure to check that all the code and output are visible before submitting your pdf to Gradescope as **points will be deducted for missing code and output that is not visible** since we will not be able to grade this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!quarto render homework_08.ipynb --cache-refresh --to pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNYoHNjeVk8S",
    "manual_problem_id": "nearsightedness_4"
   },
   "source": [
    "#### Alternative submission instructions\n",
    "\n",
    "If converting your Jupyter notebook to a pdf using the command in the cell above does not work, an alternative way to convert your Jupyter notebook is:\n",
    "\n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "2.  Under \"Download as\" (or \"Save and Export Notebook As...\") and select \"HTML (.html)\"\n",
    "3.  After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "4.  From the print window, select the option to save as a .pdf\n",
    "\n",
    "\n",
    "If you are running the assignment in a Google Colabs, you can use the following instructions: \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook and select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "2. From the print window, select the option to save as a .pdf\n",
    "3. Be sure to look over the pdf file to make sure all your code and written work is saved in a clear way.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
