{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 19: Introduction to statistical inference\n",
    "\n",
    "Plan for today:\n",
    "- Introduction to statistical inference\n",
    "- Introduction to hypothesis tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the class Jupyter setup\n",
    "\n",
    "If you have the *ydata123_2023e* environment set up correctly, you can get the class code using the code below (which presumably you've already done given that you are seeing this notebook).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(19)   # get class code    \n",
    "# YData.download.download_class_code(19, TRUE) # get the code with the answers \n",
    "\n",
    "\n",
    "YData.download_data(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also similar functions to download the homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YData.download.download_class_file('project_template.ipynb', 'homework')  # downloads the class project template (hopefully you've already done this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should install polars and the YData packages by uncommenting and running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colabs, you should also uncomment and run the code below to mount the your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Very quick example of interactive maps with plotly\n",
    "\n",
    "Last class we discussed creating choropleth maps using geopandas. Let's take a quick look at creating interactive choropleth maps in plotly. \n",
    "\n",
    "More examples of ploly maps can be [found here](https://plotly.com/python/mapbox-county-choropleth/). There are also several other packages for creating maps, such as [geoplot](https://geopandas.org/en/stable/gallery/plotting_with_geoplot.html), [leaflet, and folium](https://www.earthdatascience.org/tutorials/introduction-to-leaflet-animated-maps/), so I encourage you to explore further if you are interested. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})\n",
    "\n",
    "fig = px.choropleth_mapbox(df, geojson=counties, locations='fips', color='unemp',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 12),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical inference\n",
    "\n",
    "In statistical inference we use a smaller sample of data to make claims about a larger population of data. \n",
    "\n",
    "As an example, let's look at the [2020 election](https://www.cookpolitical.com/2020-national-popular-vote-tracker) between Donald Trump and Joe Biden, and let's focus on the results from the state of Georgia. After all the votes had been counted, the resuts showed that:\n",
    "\n",
    "- Biden received 2,461,854 votes\n",
    "- Trump received 2,473,633 votes\n",
    "\n",
    "Since we have all the votes on election data, we can precisely calculate the population parameter of the proportion of votes that Biden received, which we will denote with the symbol $\\pi_{Biden}$. \n",
    "\n",
    "Let's create names `num_trump_votes` and `num_biden_votes`, and calculate `true_prop_Biden` which is the value $\\pi_{Biden}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trump_votes = 2461854  # 2,461,854\n",
    "num_biden_votes = 2473633  # 2,473,633\n",
    "\n",
    "true_prop_Biden = num_biden_votes/(num_biden_votes + num_trump_votes)\n",
    "\n",
    "true_prop_Biden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a DataFrame called `georgia_df` that captures these election results. Each row in the DataFrame represents a votes. The column `Voted Biden` is `True` if a voter voted for Biden and `False` if the voter voted for Trump. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_votes = np.repeat(True, num_biden_votes)     # create 2,473,633 Trues for the Biden votes\n",
    "trump_votes = np.repeat(False, num_trump_votes)    # create 2,461,854 Falses for the Trump votes\n",
    "election_outcome = np.concatenate((biden_votes, trump_votes))  # put the votes together\n",
    "\n",
    "georgia_df = pd.DataFrame({\"Voted Biden\": election_outcome})  # create a DataFrame with the data\n",
    "georgia_df = georgia_df.sample(frac = 1)   # shuffle the order to make it more realistic\n",
    "\n",
    "georgia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we didn't know the actual value of $\\pi_{Biden}$ and we wanted to estimate it based on a poll of 1,000 voters. We can simulate this by using the pandas `.sample(n = )` method.\n",
    "\n",
    "Let's simulate sampling random voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 random points\n",
    "georgia_df.sample(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate proportions of voters that voted for Biden - i.e., p-hats\n",
    "\n",
    "one_sample = georgia_df.sample(1000)\n",
    "\n",
    "np.mean(one_sample['Voted Biden'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling distribution\n",
    "\n",
    "Suppose 100 polls were conducted. How many of them would show that Biden would get the majority of the vote? \n",
    "\n",
    "Let's simulate this \"sampling distribution\" of statistics now... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "sample_size = 1000\n",
    "num_simulations = 100\n",
    "\n",
    "sampling_dist = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    curr_sample = georgia_df.sample(sample_size)\n",
    "    prop_biden = np.mean(curr_sample[\"Voted Biden\"])\n",
    "    sampling_dist.append(prop_biden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sampling_dist, edgecolor = \"black\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faster way to simulate data\n",
    "\n",
    "Rather than simulating polling outcomes by pulling random samples from a DataFrame, let's simulate each vote by simulating randomly flipping a coin, where the probability of getting a \"Head\" (True value) is the probability of Biden getting a vote.\n",
    "\n",
    "To do this we can generate random numbers between 0 and 1. If a number is less than the value of $\\pi_{Biden}$, then it is a vote for Biden (i.e., a `True` value) otherwise it is a vote for Trump (`False` value). \n",
    "\n",
    "Let's generate one sample of 1,000 voters...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# usse `np.random.rand()` to generate 1,000 numbers between 0 and 1\n",
    "thousand_random_nums = np.random.rand(1000)\n",
    "\n",
    "print(thousand_random_nums[0:5])\n",
    "\n",
    "# visualize these 1,000 numbers as a histogram\n",
    "plt.hist(thousand_random_nums, edgecolor = \"black\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a vector of Booleans (True = vote for Biden, False = vote for Trump)\n",
    "\n",
    "voter_sample = thousand_random_nums <= true_prop_Biden\n",
    "\n",
    "voter_sample[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of votes for Biden in our sample\n",
    "\n",
    "# method 1\n",
    "sample_biden_prop = np.sum(voter_sample)/1000\n",
    "print(sample_biden_prop)\n",
    "\n",
    "# method 2\n",
    "sample_biden_prop2 = np.mean(voter_sample)\n",
    "print(sample_biden_prop2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate proportion of Biden voters based on a poll\n",
    "\n",
    "def generate_prop_biden(poll_size):\n",
    "    random_sample = np.random.rand(poll_size) <= true_prop_Biden\n",
    "    return np.mean(random_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# sampling distribution of many polls conducted\n",
    "\n",
    "sample_size = 1000\n",
    "num_simulations = 100\n",
    "\n",
    "sampling_dist = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    prop_biden = generate_prop_biden(sample_size)\n",
    "    sampling_dist.append(prop_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sampling_dist, edgecolor = \"black\", bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hypothesis tests\n",
    "\n",
    "In hypothesis testing, we start with a claim about a population parameter (e.g., µ = 4.2, or π = 0.25).\n",
    "\n",
    "This claim implies we should get a certain distribution of statistics, called \"The null distribution\". \n",
    "\n",
    "If our observed statistic is highly unlikely to come from the null distribution, we reject the claim. \n",
    "\n",
    "We can break down the process of running a hypothesis test into 5 steps. \n",
    "\n",
    "1. State the null and alternative hypothesis\n",
    "2. Calculate the observed statistic of interest\n",
    "3. Create the null distribution \n",
    "4. Calculate the p-value \n",
    "5. Make a decision\n",
    "\n",
    "Let's run through these steps now!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: State the null and alternative hypothesis\n",
    "\n",
    "$H_0: \\pi = 0.5$\n",
    "\n",
    "$H_A: \\pi < 0.5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate the observed statistic of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data to a smaller number of columns: \"title\" and \"binary\"\n",
    "\n",
    "movies_smaller = movies[[\"title\", \"binary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of movies that pass the Bechdel test\n",
    "\n",
    "booleans_passed = movies_smaller[\"binary\"] == \"PASS\"\n",
    "\n",
    "prop_passed = np.mean(booleans_passed)\n",
    "\n",
    "prop_passed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create the null distribution \n",
    "\n",
    "We need to create a null distribution, which is the distribution of statistics we would expect to get if the null hypothesis is true. \n",
    "\n",
    "**Question**: about what percent of the movies would we expect to pass the Bechdel test if the null distribution was true? \n",
    "\n",
    "**Answer**: 50%\n",
    "\n",
    "Let's create simulated data that is consistent with this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate one proportion consistent with the null hypothesis\n",
    "\n",
    "n = movies.shape[0]\n",
    "print(n)\n",
    "\n",
    "null_sample = np.random.rand(n) < .5\n",
    "\n",
    "np.mean(null_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a function to generate a proportions consistent with a null hypothesis\n",
    "\n",
    "def generate_prop_bechdel(n, null_prop):\n",
    "    random_sample = np.random.rand(n) <= null_prop\n",
    "    return np.mean(random_sample)\n",
    "\n",
    "generate_prop_bechdel(1794, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a null distribution \n",
    "\n",
    "null_dist = []\n",
    "\n",
    "for i in range(10000):    \n",
    "    null_dist.append(generate_prop_bechdel(1794, .5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution \n",
    "\n",
    "plt.hist(null_dist, edgecolor = \"black\", bins = 20) #, range = (.4, .6));\n",
    "plt.plot(prop_passed, 30, '.', markersize = 30, color = \"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate the p-value \n",
    "\n",
    "Calculate the proportion of points in the null distribution that are more extreme than the observed statistic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "\n",
    "stats_more_extreme = np.array(null_dist) <= prop_passed\n",
    "\n",
    "print(stats_more_extreme[0:5])\n",
    "\n",
    "p_value = np.mean(stats_more_extreme)\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Make a decision\n",
    "\n",
    "Since the p-value is very small (essentially zero) it is very unlikely that our statistic come from the null distribution. Thus we will reject the null hypothesis and conclude that less than 50% of movies pass the Bechdel test. \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-ydata123_2023e]",
   "language": "python",
   "name": "conda-env-anaconda3-ydata123_2023e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
