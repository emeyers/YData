{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 26: Unsupervised learning\n",
    "\n",
    "Plan for today:\n",
    "- Hierarchical clustering\n",
    "- Quick demo of using an LLM/chatbot in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the class Jupyter setup\n",
    "\n",
    "If you have the *ydata123_2024a* environment set up correctly, you can get the class code using the code below (which presumably you've already done given that you are seeing this notebook).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(26)   # get class code    \n",
    "# YData.download.download_class_code(26, TRUE) # get the code with the answers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should install the YData packages by uncommenting and running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colabs, you should also uncomment and run the code below to mount the your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unsupervised learning: Hierarchical clustering\n",
    "\n",
    "In unsupervised machine learning, we try to find patterns in the data using only a set of features X (without any labels y). \n",
    "\n",
    "Let's explore clustering which is a form of unsupervised learning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "\n",
    "penguins = penguins.dropna()\n",
    "\n",
    "penguins = penguins.sample(frac = 1)\n",
    "\n",
    "\n",
    "# get the features and the labels\n",
    "X_penguin_features = penguins[['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g']]\n",
    "y_penguin_labels = penguins['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do k-means clustering in scikit-learn using the `KMeans()` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "#  Ward's method adds points to a cluster that minimizes the sum of squared differences \n",
    "# within all clusters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a dendrogram\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster points into 3 clusters \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the predicted cluster for each point\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize how well the clustering matches the penguin species\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chatbots \n",
    "\n",
    "Large language models (LLMs) are taking over the world. I, for one, welcome our new robot [overlords](https://www.youtube.com/watch?v=8lcUHQYhPTE).\n",
    "\n",
    "Let's explore how we can use a model from HuggingFace to create a chatbot.\n",
    "\n",
    "To do this we need to install some additional packages. I recommend cloning your Jupyter environment, and then adding these packages to the new environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the code in this cell and RUN IT ONLY ONCE to create a new conda environment \n",
    "# that will have the packages necessary to create a chatbot\n",
    "\n",
    "# Note: this might not work. I recommend only trying this after you've finished all \n",
    "# the rest of the work for the class - i.e., after you've turned in your final project\n",
    "\n",
    "#!conda create --name ydata123_2024c --clone ydata123_2024a\n",
    "#!conda activate ydata123_2024c\n",
    "#!conda install conda-forge::transformers -y\n",
    "#!conda install pytorch::pytorch==2.2.2\n",
    "#!conda install conda-forge::tensorflow -y\n",
    "#!conda install conda-forge::flax -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:49:00.972990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/em939/anaconda3/envs/ydata123_2024a/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Modified from code created by Giuliano Formisano\n",
    "\n",
    "# load libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline, Conversation\n",
    "\n",
    "# load conversational pipeline\n",
    "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Who is better the Boston Red Sox or New York Yankees?\n",
      "Chatbot:  I would have to say the red sox. They have been around since 1903.\n"
     ]
    }
   ],
   "source": [
    "# set user input\n",
    "user_input = \"Hi! What can you do?\" # add your prompt here\n",
    "\n",
    "# generate response using pipeline\n",
    "response = chatbot(user_input)\n",
    "\n",
    "# print results\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Chatbot: {response[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for an interaction User-Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# Loop of interaction user-chatbot\n",
    "while True:\n",
    "  user_input = input(\"You: \") # add prompt in the appearing box below\n",
    "  if user_input.lower() == \"quit\": # write \"quit\" to interrupt\n",
    "    break\n",
    "  response = chatbot(user_input) # this is a bit slow\n",
    "  print(f\"Chatbot: {response[0]['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
