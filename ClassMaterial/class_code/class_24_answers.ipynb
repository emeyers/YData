{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 24: Classification\n",
    "\n",
    "Plan for today:\n",
    "- Classification features\n",
    "- Introduction to Machine Learning\n",
    "- KNN classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the class Jupyter setup\n",
    "\n",
    "If you have the *ydata123_2024a* environment set up correctly, you can get the class code using the code below (which presumably you've already done given that you are seeing this notebook).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(24)   # get class code    \n",
    "# YData.download.download_class_code(24, TRUE) # get the code with the answers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also similar functions to download the homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YData.download.download_homework(9)  # downloads the homework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should install the YData packages by uncommenting and running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colabs, you should also uncomment and run the code below to mount the your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro to Machine Learning:  Features (X) and labels (y)\n",
    "\n",
    "In supervised machine learning, we use a computer algorithm called a \"pattern classifier\" to learn relationships between a set of features X, and a label y. When the classifier is given new examples X, it can then make new predictions y. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>35.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>189.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>37.7</td>\n",
       "      <td>18.7</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>41.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>201.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "48      Adelie   Dream            36.0           17.9              190.0   \n",
       "218  Chinstrap   Dream            50.8           19.0              210.0   \n",
       "22      Adelie  Biscoe            35.9           19.2              189.0   \n",
       "21      Adelie  Biscoe            37.7           18.7              180.0   \n",
       "151     Adelie   Dream            41.5           18.5              201.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "48        3450.0  Female  \n",
       "218       4100.0    Male  \n",
       "22        3800.0  Female  \n",
       "21        3600.0    Male  \n",
       "151       4000.0    Male  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "\n",
    "penguins = penguins.dropna()\n",
    "\n",
    "penguins = penguins.sample(frac = 1)\n",
    "\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the classification process, let's store the features (X) and the labels (y) in separate names called `X_penguin_features` and `y_penguin_labels` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features and the labels\n",
    "\n",
    "X_penguin_features = penguins[['bill_length_mm', \n",
    "                               'bill_depth_mm',\n",
    "                               'flipper_length_mm', \n",
    "                               'body_mass_g']]\n",
    "\n",
    "y_penguin_labels = penguins['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore classification, let's use a k-Nearest Neighbors classifier to predict the species of a penguin based on particular features the penguin has such as the penguin's bill length and body mass. \n",
    "\n",
    "Let's construct a K-Nearest Neighbor classifier (KNN) using 5 neighbors for predictions (i.e., k = 5 so we are using a 5-Nearest Neighbor classifier). \n",
    "\n",
    "We can do this using the `KNeighborsClassifier(n_neighbors = )` function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Adelie' 'Gentoo'\n",
      " 'Gentoo' 'Adelie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8378378378378378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Construct a classifier a 5 nearest neighbor classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5) \n",
    "\n",
    "\n",
    "# Use the .fit() method “train” the classifier \n",
    "# (for a KNN classifier \"training the classifier\" just involves memorizing the training data)\n",
    "knn.fit(X_penguin_features, y_penguin_labels) \n",
    "\n",
    "\n",
    "# Use the .predict() method to make predictions\n",
    "penguin_preditions = knn.predict(X_penguin_features)\n",
    "print(penguin_preditions[0:10])\n",
    "\n",
    "\n",
    "# get the classification accuracy\n",
    "np.mean(penguin_preditions == y_penguin_labels)\n",
    "\n",
    "\n",
    "# Since we train and test the classifier with the same data, we don't get an accurate estimate \n",
    "# of how well the classifier will do at making predictions on new data. \n",
    "# This can clearly be seen when we set k = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-validation\n",
    "\n",
    "To avoid over-fitting, we need to split our data into a training and test set. \n",
    "\n",
    "The classifier \"learns\" the relationship between features (X) and labels (y) on the **training set**.\n",
    "\n",
    "The classifier makes predictions on the features (X) of the **test set**. \n",
    "\n",
    "We compare the classifier's predictions on the test features (X) to the actual labels y, to get a more accuracy assessment of the **classification accuracy**.\n",
    "\n",
    "\n",
    "Let's try this now...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 4)\n",
      "(83, 4)\n"
     ]
    }
   ],
   "source": [
    "# manually create a training with 250 examples, and a test set that has the rest of the data\n",
    "\n",
    "X_train_manual = X_penguin_features.iloc[0:250, :]\n",
    "y_train_manual = y_penguin_labels.iloc[0:250]\n",
    "\n",
    "X_test_manual = X_penguin_features.iloc[250:, :]\n",
    "y_test_manual = y_penguin_labels.iloc[250:]\n",
    "\n",
    "\n",
    "print(X_train_manual.shape)\n",
    "print(X_test_manual.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the scikit-learn `train_test_split()` function to generate training and test splits of our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 4)\n",
      "(84, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>39.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>39.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>50.2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "50             39.6           17.7              186.0       3500.0\n",
       "30             39.5           16.7              178.0       3250.0\n",
       "210            50.2           18.8              202.0       3800.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into a training and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_penguin_features,  \n",
    "                                                    y_penguin_labels, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# construct a classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 1) \n",
    "\n",
    "# “train” the classifier (which for a KNN classifier just involves memorizing the training data)\n",
    "knn.fit(X_train_manual, y_train_manual) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie', 'Adelie', 'Chinstrap', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Chinstrap', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Chinstrap', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Chinstrap', 'Chinstrap', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Gentoo', 'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Gentoo', 'Adelie', 'Adelie'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the predictions\n",
    "\n",
    "penguin_preditions = knn.predict(X_test_manual)\n",
    "\n",
    "penguin_preditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554216867469879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prediction accuracy \n",
    "\n",
    "np.mean(penguin_preditions == y_test_manual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554216867469879"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the classifier on the test set using the .score() method\n",
    "\n",
    "knn.score(X_test_manual, y_test_manual) # prediction accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we test the classifier on the training set? \n",
    "\n",
    "knn.score(X_train_manual, y_train_manual) # prediction accuracy on the training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation\n",
    "\n",
    "In k-fold cross-validation we split our data into k-parts (note, the k here has no relation to the k in k-Nearest Neighbor - it is just that k is a frequent letter to use in math to denote integer values).  \n",
    "\n",
    "To run a k-fold cross-validation analysis, we train the classifier on k-1 parts of the data and test it on the remaining part. We repeat this process k times to get k classification accuracies. We then take the average of these results as our estimate of our overall classification accuracy. \n",
    "\n",
    "We can use the scikit-learn `cross_val_score()` to easily do this...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8358209  0.89552239 0.8358209  0.87878788 0.86363636]\n",
      "0.861917684305744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 1) # construct knn classifier\n",
    "\n",
    "# do 5-fold cross-validation\n",
    "scores = cross_val_score(knn, X_penguin_features,  y_penguin_labels, cv = 5)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other classifiers\n",
    "\n",
    "Many other types of classifiers that have been created. Scikit-learn makes it very easy to try out a range of classifiers. \n",
    "\n",
    "Let's explore the Support Vector Machine, and Random Forest Classifier on our penguin data...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6317051108095885\n"
     ]
    }
   ],
   "source": [
    "# Suppress ConvergenceWarning - please ignore this code \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# Try a support vector machine (SVM)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()   # max_iter=10000\n",
    "\n",
    "scores = cross_val_score(svm, X_penguin_features,  y_penguin_labels, cv = 5)\n",
    "\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698778833107191\n"
     ]
    }
   ],
   "source": [
    "# Try a random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(random_forest, X_penguin_features,  y_penguin_labels, cv = 5)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the KNN classifier\n",
    "\n",
    "So far we have used the KNN classifier (and a few other classifiers). Let's now see if we can write code that will implement the KNN classifier.\n",
    "\n",
    "We will do this by writing a several helper functions that build on each other. These functions are: \n",
    "\n",
    "1. `euclid_dist(x1, x2)`: finds the Euclidean distance between two points `x1` and `x2`\n",
    "\n",
    "2. `get_labels_and_distances(test_point, X_train_features, y_train_labels)`: This function finds the distance between a test point and all the training points. It returns a DataFrame with the distance from all training points and the training labels for each point.\n",
    "\n",
    "3. `classify_point(test_point, k, X_train_features, y_train_labels)`: Classifies which class a test point belongs to\n",
    "\n",
    "4. `classify_all_test_data(X_test_data, k, X_train_features, y_train_labels)`: Classifiers which class all test points below to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing a function that can get the Euclidean distance between two points `x` and `z`: \n",
    "\n",
    "$$dist(x, z) = \\sqrt{\\Sigma_{i = 1}^d (x_i - z_i)^2)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclid_dist(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "# test our function \n",
    "my_vec1 = np.array([1, 2, 3, 4])\n",
    "my_vec2 = np.array([2, 3, 4, 5])\n",
    "\n",
    "euclid_dist(my_vec1, my_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>450.741167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>700.801035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>150.219606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>650.746494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>151.810968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label    distance\n",
       "50      Adelie  450.741167\n",
       "30      Adelie  700.801035\n",
       "210  Chinstrap  150.219606\n",
       "38      Adelie  650.746494\n",
       "67      Adelie  151.810968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now write a function that returns the labels and distances \n",
    "# between a training point and all the test points\n",
    "\n",
    "\n",
    "def get_labels_and_distances(test_point, X_train_features, y_train_labels):\n",
    "    \n",
    "    the_distances = []\n",
    "    \n",
    "    # get the distance between the test point and all training points\n",
    "    for i in range(X_train_features.shape[0]):\n",
    "        the_distances.append(euclid_dist(test_point, X_train_features.iloc[i]))\n",
    "\n",
    "    \n",
    "    # add the training labels and distances on to a DataFrame \n",
    "    labels_and_distances = pd.DataFrame({'label': y_train_labels})\n",
    "    labels_and_distances['distance'] = the_distances \n",
    "\n",
    "    return labels_and_distances\n",
    "\n",
    "\n",
    "test_data_point = X_test.iloc[0]\n",
    "test_label = y_test.iloc[0]\n",
    "\n",
    "labels_and_distances = get_labels_and_distances(test_data_point, X_train, y_train)\n",
    "\n",
    "labels_and_distances.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>4.940648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>8.793748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>9.327915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>12.701575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>22.456402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label   distance\n",
       "212  Chinstrap   4.940648\n",
       "260     Gentoo   8.793748\n",
       "203  Chinstrap   9.327915\n",
       "157  Chinstrap  12.701575\n",
       "36      Adelie  22.456402"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the k closest neighbors\n",
    "\n",
    "k = 5\n",
    "\n",
    "sorted_labels_dist = labels_and_distances.sort_values(\"distance\")\n",
    "\n",
    "sorted_labels_dist = sorted_labels_dist.iloc[0:k]\n",
    "\n",
    "sorted_labels_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinstrap'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the majority label\n",
    "\n",
    "count_table = sorted_labels_dist.groupby(\"label\").count().reset_index()\n",
    "\n",
    "sorted_count_table = count_table.sort_values(\"distance\", ascending = False)\n",
    "\n",
    "sorted_count_table.iloc[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinstrap\n",
      "Chinstrap\n"
     ]
    }
   ],
   "source": [
    "# write a function to do the classification on a test point \n",
    "# by putting together all the pieces\n",
    "\n",
    "def classify_point(test_point, k, X_train_features, y_train_labels):\n",
    "    \n",
    "    labels_and_distances =  get_labels_and_distances(test_point, \n",
    "                                                     X_train_features, \n",
    "                                                     y_train_labels)\n",
    "\n",
    "    sorted_labels_dist = labels_and_distances.sort_values(\"distance\")\n",
    "    sorted_labels_dist = sorted_labels_dist.iloc[0:k]\n",
    "    \n",
    "    \n",
    "    count_table = sorted_labels_dist.groupby(\"label\").count().reset_index()\n",
    "    sorted_count_table = count_table.sort_values(\"distance\", ascending = False)\n",
    "    majority_class = sorted_count_table.iloc[0][\"label\"]\n",
    "    \n",
    "    return majority_class\n",
    "\n",
    "\n",
    "\n",
    "prediction = classify_point(test_data_point, 5, X_train, y_train)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinstrap', 'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify a full test set\n",
    "\n",
    "def classify_all_test_data(X_test_data, k, X_train_features, y_train_labels):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(X_test_data.shape[0]):\n",
    "        \n",
    "        curr_test_point = X_test_data.iloc[i]\n",
    "        \n",
    "        curr_prediction = classify_point(curr_test_point, \n",
    "                                         k, \n",
    "                                         X_train_features, \n",
    "                                         y_train_labels)\n",
    "        \n",
    "        predictions.append(curr_prediction)\n",
    "\n",
    "    return np.array(predictions)\n",
    "    \n",
    "    \n",
    "all_predictions = classify_all_test_data(X_test, 5, X_train, y_train)\n",
    "\n",
    "all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the classification accuracy\n",
    "\n",
    "np.mean(all_predictions == y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus material:  Feature normalization\n",
    "\n",
    "If you look at the features we have been using in our analyses, you will notice that they are on very different scales. This is quite problematic for a KNN classifier since the classifier is finding the distance between each data point, so features that have large values will dominate this distance. \n",
    "\n",
    "Let's explore the scales that different features have by looking at some descriptive statistics. In particular, let's go back to the manually created `X_train`, `X_test`, `y_train`, `y_test` to examine the scale that different features are measured on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.072691</td>\n",
       "      <td>17.202008</td>\n",
       "      <td>200.694779</td>\n",
       "      <td>4191.064257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.548566</td>\n",
       "      <td>1.975463</td>\n",
       "      <td>14.168742</td>\n",
       "      <td>815.789230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.300000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.200000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>3950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.700000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6050.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "count      249.000000     249.000000         249.000000   249.000000\n",
       "mean        44.072691      17.202008         200.694779  4191.064257\n",
       "std          5.548566       1.975463          14.168742   815.789230\n",
       "min         32.100000      13.100000         172.000000  2700.000000\n",
       "25%         39.300000      15.600000         190.000000  3550.000000\n",
       "50%         45.200000      17.300000         197.000000  3950.000000\n",
       "75%         48.700000      18.800000         213.000000  4750.000000\n",
       "max         59.600000      21.500000         231.000000  6050.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the training and test splots of the data using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_penguin_features,  \n",
    "                                                    y_penguin_labels, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Get summary statistics of the training data using the .describe() method\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a z-score transformation of our features which set the mean of the features to 0 and the standard deviation to 1. We can do this using the using the `StandardScaler()` object as follows: \n",
    "\n",
    "1. Create a new `StandardScaler()` object using `scalar = StandardScaler()` \n",
    "\n",
    "2. Have the `scalar` object learn the means and standard deviations of our training data by calling the `scalar.fit(X)` function on the training data.\n",
    "\n",
    "3. Use the fit `scalar` object to transform both the training and test features so that all features are on a similar scale by calling the `.transform(X)` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# learning the mean and standard deviations to scale the features\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "scalar.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-score transform the features \n",
    "\n",
    "X_train_transformed = scalar.transform(X_train)\n",
    "X_test_transformed = scalar.transform(X_test)\n",
    "\n",
    "type(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at our transformed training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>2.490000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.554312e-15</td>\n",
       "      <td>1.752280e-15</td>\n",
       "      <td>-2.496887e-16</td>\n",
       "      <td>-3.566982e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002014e+00</td>\n",
       "      <td>1.002014e+00</td>\n",
       "      <td>1.002014e+00</td>\n",
       "      <td>1.002014e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.162145e+00</td>\n",
       "      <td>-2.080661e+00</td>\n",
       "      <td>-2.029296e+00</td>\n",
       "      <td>-1.831438e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.618989e-01</td>\n",
       "      <td>-8.125864e-01</td>\n",
       "      <td>-7.563353e-01</td>\n",
       "      <td>-7.874037e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.035805e-01</td>\n",
       "      <td>4.970446e-02</td>\n",
       "      <td>-2.612950e-01</td>\n",
       "      <td>-2.960934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.356445e-01</td>\n",
       "      <td>8.105493e-01</td>\n",
       "      <td>8.702258e-01</td>\n",
       "      <td>6.865272e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.804073e+00</td>\n",
       "      <td>2.180070e+00</td>\n",
       "      <td>2.143187e+00</td>\n",
       "      <td>2.283286e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm   body_mass_g\n",
       "count    2.490000e+02   2.490000e+02       2.490000e+02  2.490000e+02\n",
       "mean     1.554312e-15   1.752280e-15      -2.496887e-16 -3.566982e-17\n",
       "std      1.002014e+00   1.002014e+00       1.002014e+00  1.002014e+00\n",
       "min     -2.162145e+00  -2.080661e+00      -2.029296e+00 -1.831438e+00\n",
       "25%     -8.618989e-01  -8.125864e-01      -7.563353e-01 -7.874037e-01\n",
       "50%      2.035805e-01   4.970446e-02      -2.612950e-01 -2.960934e-01\n",
       "75%      8.356445e-01   8.105493e-01       8.702258e-01  6.865272e-01\n",
       "max      2.804073e+00   2.180070e+00       2.143187e+00  2.283286e+00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view descriptive statistics on the transformed features\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, \n",
    "                                      columns = X_train.columns)\n",
    "\n",
    "X_train_transformed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our classification accuracy changes using the z-score transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply KNN classification on the normalized features\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 1) \n",
    "knn.fit(X_train_transformed, y_train)\n",
    "knn.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to transform our features inside a cross-validation loop, we can set up a pipeline. This pipeline will do the following:\n",
    "\n",
    "1. It will split the data into a training and test set\n",
    "2. It will fit the transformation of the features on the training set (i.e., learn the means and standard deviations on the training set). \n",
    "3. It will apply a z-score transformation of the training and test set based on the features learned in step 2\n",
    "4. It will train the classifier on the transformed data\n",
    "5. It will measure the classification accuracy on the test data\n",
    "6. It will repeat this process k times, where k here refers to how many cross-validation splits we are using\n",
    "\n",
    "In order to do this in scikit-learn we can use a `Pipeline` object which sets up the stages of transformation and classification, along with a `KFold` object which will run the cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9909543193125282"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# create a pipeline for running cross-validation with feature normalization\n",
    "\n",
    "# components that go into the pipeline\n",
    "scalar = StandardScaler()\n",
    "knn = KNeighborsClassifier(n_neighbors = 1) \n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "# build the pipeline\n",
    "pipeline = Pipeline([('transformer', scalar), ('estimator', knn)])\n",
    "\n",
    "# get the cross-validation scores\n",
    "scores = cross_val_score(pipeline, \n",
    "                         X_penguin_features, \n",
    "                         y_penguin_labels, \n",
    "                         cv = cv)\n",
    "\n",
    "\n",
    "# print out the mean score over the 5 cross-validation splits\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
