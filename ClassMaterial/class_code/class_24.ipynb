{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 24: Unsupervised learning\n",
    "\n",
    "Plan for today:\n",
    "- Clustering\n",
    "- Object-oriented programming\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(24)   # get class code    \n",
    "# YData.download.download_class_code(24, TRUE) # get the code with the answers \n",
    "\n",
    "# YData.download.download_homework(9)  # downloads the homework \n",
    "\n",
    "# project review template\n",
    "# YData.download.download_class_file('reviewer_template.ipynb', 'homework')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress ConvergenceWarning - please ignore this code \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our penguin data that we can use to test that our code is working properly\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.dropna()\n",
    "penguins = penguins.sample(frac = 1)\n",
    "\n",
    "X_penguin_features = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y_penguin_labels = penguins['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unsupervised learning: clustering\n",
    "\n",
    "We can do k-means clustering in scikit-learn using the `KMeans()` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# fit k-means with 3 clusters \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which cluster each point belongs to \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a matrix of which penguin types end up in which cluster \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# do clustering with feature normalization \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which cluster each (normalized) point belongs to\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a matrix of which penguin types end up in which cluster \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Unsupervised learning: Hierarchical clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "#  Ward's method adds points to a cluster that minimizes the sum of squared differences within all clusters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a dendrogram\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster points into 3 clusters \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the predicted cluster for each point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize how well the clustering matches the penguin species\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object-oriented programming\n",
    "\n",
    "[Object-oriented programming (OOP)](https://en.wikipedia.org/wiki/Object-oriented_programming) is a programming paradigm based on the concept of objects, which can contain data and code: data in the form of fields (often known as attributes or properties), and code in the form of procedures (often known as methods). In OOP, computer programs are designed by making them out of objects that interact with one another.\n",
    "\n",
    "Let's write our own K-Nearest Neighbor class that can create K-Nearest Neighbor classifiers!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN functions\n",
    "\n",
    "Below are the functions we previously wrote in class 22 to do K-Nearest Neighbor classification. \n",
    "\n",
    "We will now turn this code into a KNN object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_penguin_features,  \n",
    "                                                    y_penguin_labels, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinstrap', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From class 22\n",
    "\n",
    "# Calculate the Euclidean distance\n",
    "def euclid_dist(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "# Get the labels and distances between a test point and all the training data\n",
    "def get_labels_and_distances(test_point, X_train_features, y_train_labels):\n",
    "    \n",
    "    the_distances = []\n",
    "    \n",
    "    # get the distance between the test point and all training points\n",
    "    for i in range(X_train_features.shape[0]):\n",
    "        the_distances.append(euclid_dist(test_point, X_train_features.iloc[i]))\n",
    "\n",
    "    \n",
    "    # Create a DataFrame with the training labels and distances \n",
    "    labels_and_distances = pd.DataFrame({'label': y_train_labels, 'distance':the_distances})\n",
    "    return labels_and_distances\n",
    "\n",
    "\n",
    "\n",
    "# Classify a single test point\n",
    "def classify_point(test_point, k, X_train_features, y_train_labels):\n",
    "    \n",
    "    labels_and_distances =  get_labels_and_distances(test_point, \n",
    "                                                     X_train_features, \n",
    "                                                     y_train_labels)\n",
    "\n",
    "    sorted_labels_dist = labels_and_distances.sort_values(\"distance\")\n",
    "    sorted_labels_dist = sorted_labels_dist.iloc[0:k]\n",
    "    \n",
    "    \n",
    "    count_table = sorted_labels_dist.groupby(\"label\").count().reset_index()\n",
    "    sorted_count_table = count_table.sort_values(\"distance\", ascending = False)\n",
    "    majority_class = sorted_count_table.iloc[0][\"label\"]\n",
    "    \n",
    "    return majority_class\n",
    "\n",
    "\n",
    "\n",
    "# Classify a whole test set\n",
    "def classify_all_test_data(X_test_data, k, X_train_features, y_train_labels):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(X_test_data.shape[0]):\n",
    "        \n",
    "        curr_test_point = X_test_data.iloc[i]\n",
    "        \n",
    "        curr_prediction = classify_point(curr_test_point, \n",
    "                                         k, \n",
    "                                         X_train_features, \n",
    "                                         y_train_labels)\n",
    "        \n",
    "        predictions.append(curr_prediction)\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "all_predictions = classify_all_test_data(X_test, 5, X_train, y_train)\n",
    "\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object constructor\n",
    "\n",
    "To start, let's write the \"constructor\" code that can be used to create a new KNN object. This code will simply store the number of neighbors used in a field called `k`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_neighbors): \n",
    "\n",
    "        ...  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value stored property k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The .fit() method\n",
    "\n",
    "Let's now write the `.fit()` method. This method will merely store the training and test data into fields called `X_train` and `y_train`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_neighbors): \n",
    "        self.k = n_neighbors \n",
    "\n",
    "    # The fit method\n",
    "    def fit(self, X_features_train, y_labels_train):\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an KNN object and try the .fit() method \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The .predict() method\n",
    "\n",
    "Now let's write the `.predict()` method which will take a test data set `X_test` and will make predictions for which class each test point belongs to. \n",
    "\n",
    "To do this we will cheat a little and use the classification functions we wrote previous (i.e., the functions above). We could also just include these functions into our object (i.e., cut and paste them into our object). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_neighbors): \n",
    "        self.k = n_neighbors \n",
    "\n",
    "    # The fit method\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # The predict method\n",
    "    def predict(self, X_test_data):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an KNN object and try the .predict() method \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special methods\n",
    "\n",
    "\"Special methods\" (also known as \"dunder methods\") allow objects to work in consistent/predictable ways. \n",
    "\n",
    "Let's add a method that makes it so our KNN object displays more useful information when we call the `print()` function on it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.KNN'>\n"
     ]
    }
   ],
   "source": [
    "# What is printed when we call the print() function on our current KNN object\n",
    "\n",
    "print(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_neighbors): \n",
    "        self.k = n_neighbors \n",
    "\n",
    "    # The fit method\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # The predict method\n",
    "    def predict(self, X_test_data):\n",
    "        return classify_all_test_data(X_test_data, self.k, self.X_train, self.y_train)\n",
    "\n",
    "    # The print \"special\" method\n",
    "    def __str__(self):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the print() method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![](https://theenglishtree.it/wp-content/uploads/2016/10/Untitled.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ydata123_2024f] *",
   "language": "python",
   "name": "conda-env-ydata123_2024f-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
