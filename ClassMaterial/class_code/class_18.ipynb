{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 18: Introduction to statistical inference\n",
    "\n",
    "Plan for today:\n",
    "- Writing a function to simulate flipping a coin\n",
    "- Introduction to statistical inference\n",
    "- Introduction to hypothesis tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file `movies.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n",
      "The file `daily_bike_totals.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n"
     ]
    }
   ],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(18)   # get class code    \n",
    "# YData.download.download_class_code(18, TRUE) # get the code with the answers \n",
    "\n",
    "# YData.download.download_class_file('project_template.ipynb', 'homework')  # downloads the class project template \n",
    "# YData.download_homework(7)  # downloads the 7th homework \n",
    "\n",
    "YData.download_data(\"movies.csv\")\n",
    "YData.download_data(\"daily_bike_totals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are using Google Colabs, you should install the YData packages and mount the your google drive by uncommenting and running the code below.\n",
    "\n",
    "# !pip install https://github.com/emeyers/YData_package/tarball/master\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Warm-up exercise: writing functions\n",
    "\n",
    "For pracice writing functions, let's write a function that will mimic flipping coins. This function will be useful when we start talking about statistical inference. \n",
    "\n",
    "In particular, let's write a function called `flip_coins(n, prob)` which will simulate flipping a coin `n` times where:\n",
    "- `n` is the number of times we have flipped the coin\n",
    "- `prob` is the probability that each coin flip will return \"head\"\n",
    "\n",
    "The function should return the number of \"heads\" that occurred from flipping the coin `n` times; i.e., it should return a number between 0, which means no heads occurred, and `n` which means a \"head\" occurred on every flip. \n",
    "\n",
    "When writing functions, it is often useful to write the bulk of the code outside of a function and then turn in into a function by wrapping your code in a `def` statement. Let's go through a few steps of writing this function now. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Generating random numbers between 0 and 1\n",
    "\n",
    "We can use the numpy function `np.random.rand(n)` to generate `n` random numbers. Please create a name called `n` and set it equal to 500 to simulate 500 random coin flips. Then use the name `n`, along with the `np.random.rand(n)` to generate 500 random numbers between 0 and 1. Save these random numbers to the name `rand_nums`. \n",
    "\n",
    "Finally, to see what these numbers look like, visualize `rand_nums` using a histogram. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.rand() to generate n = 500 random numbers between 0 and 1, and visualize them as a histogram. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Count the number of \"heads\"\n",
    "\n",
    "Next create a name called `prob` which has the probability that a coin flip is a \"head\". Let's set `prob` to be equal to .5 to simulate flipping a fair coin. Then see how many of the `rand_nums` are less than the `prob` value to see how many of your coin flips were \"head\"; i.e., use `np.sum()` to count how many of your coin flips were heads. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prob to .5 and count how many values are greater than prob\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Creating the function flip_coins(n, prob)\n",
    "\n",
    "Now write the function `flip_coins(n, prob)` by taking the code you wrote in the previous two steps and turning it into a function. \n",
    "\n",
    "Then try out the function a few times and see how the number of \"heads\" you get varies from simulation to simulation, and also experiment with different values for the arguments `n` and `prob`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function flip_coins(n, prob) that generates n random numbers and returns how many are less than prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Adding an additional argument to the function \n",
    "\n",
    "Let's add an additional parameter to the `flip_coins` function called `return_prop` which has a default value of `False`; i.e., the function should now be `flip_coins(n, prob, return_prop = False)`. If the `return_prop` is set to `True` that it should return the proportion of coin flips that were heads rather than the number of coin flips that were heads. \n",
    "\n",
    "Hint: Adding a conditional statement to your function could be useful. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an argument return_prop that when set to True will return the proporton of coin flips that were heads (rather than the number of heads)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Statistical inference\n",
    "\n",
    "In statistical inference we use a smaller sample of data to make claims about a larger population of data. \n",
    "\n",
    "As an example, let's look at the [2020 election](https://www.cookpolitical.com/2020-national-popular-vote-tracker) between Donald Trump and Joe Biden, and let's focus on the results from the state of Georgia. After all the votes had been counted, the resuts showed that:\n",
    "\n",
    "- Biden received 2,461,854 votes\n",
    "- Trump received 2,473,633 votes\n",
    "\n",
    "Since we have all the votes on election data, we can precisely calculate the population parameter of the proportion of votes that Biden received, which we will denote with the symbol $\\pi_{Biden}$. \n",
    "\n",
    "Let's create names `num_trump_votes` and `num_biden_votes`, and calculate `true_prop_Biden` which is the value $\\pi_{Biden}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trump_votes = 2461854  # 2,461,854\n",
    "num_biden_votes = 2473633  # 2,473,633\n",
    "\n",
    "\n",
    "# calculate the proportion of people who voted for Biden\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a DataFrame called `georgia_df` that captures these election results. Each row in the DataFrame represents a votes. The column `Voted Biden` is `True` if a voter voted for Biden and `False` if the voter voted for Trump. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voted Biden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1098809</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123381</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880480</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075598</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915724</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Voted Biden\n",
       "1098809         True\n",
       "4123381        False\n",
       "4880480        False\n",
       "2075598         True\n",
       "2915724        False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_votes = np.repeat(True, num_biden_votes)     # create 2,473,633 Trues for the Biden votes\n",
    "trump_votes = np.repeat(False, num_trump_votes)    # create 2,461,854 Falses for the Trump votes\n",
    "election_outcome = np.concatenate((biden_votes, trump_votes))  # put the votes together\n",
    "\n",
    "georgia_df = pd.DataFrame({\"Voted Biden\": election_outcome})  # create a DataFrame with the data\n",
    "georgia_df = georgia_df.sample(frac = 1)   # shuffle the order to make it more realistic\n",
    "\n",
    "georgia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we didn't know the actual value of $\\pi_{Biden}$ and we wanted to estimate it based on a poll of 1,000 voters. We can simulate this by using the pandas `.sample(n = )` method.\n",
    "\n",
    "Let's simulate sampling random voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 random points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate proportions of voters that voted for Biden - i.e., p-hats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Creating a sampling distribution via taking random samples\n",
    "\n",
    "Suppose 100 polls were conducted. How many of them would show that Biden would get the majority of the vote? \n",
    "\n",
    "Let's simulate this \"sampling distribution\" of statistics now... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 1 μs, total: 3 μs\n",
      "Wall time: 3.58 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the sampling distribution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Creating a sampling distributions via coin flips (a faster way to simulate data)\n",
    "\n",
    "Rather than simulating polling outcomes by pulling random samples from a DataFrame, let's simulate each vote by simulating randomly flipping a coin, where the probability of getting a \"Head\" (True value) is the probability of Biden getting a vote.\n",
    "\n",
    "To do this we can use our `flip_coins(n, prob_heads, return_prop)` function we wrote in the warm-up exercises above. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.1 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# sampling distribution of many polls conducted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis tests\n",
    "\n",
    "In hypothesis testing, we start with a claim about a population parameter (e.g., µ = 4.2, or π = 0.25).\n",
    "\n",
    "This claim implies we should get a certain distribution of statistics, called \"The null distribution\". \n",
    "\n",
    "If our observed statistic is highly unlikely to come from the null distribution, we reject the claim. \n",
    "\n",
    "We can break down the process of running a hypothesis test into 5 steps. \n",
    "\n",
    "1. State the null and alternative hypothesis\n",
    "2. Calculate the observed statistic of interest\n",
    "3. Create the null distribution \n",
    "4. Calculate the p-value \n",
    "5. Make a decision\n",
    "\n",
    "Let's run through these steps now!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: State the null and alternative hypothesis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate the observed statistic of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>imdb</th>\n",
       "      <th>title</th>\n",
       "      <th>test</th>\n",
       "      <th>clean_test</th>\n",
       "      <th>binary</th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>intgross</th>\n",
       "      <th>code</th>\n",
       "      <th>...</th>\n",
       "      <th>director</th>\n",
       "      <th>released</th>\n",
       "      <th>actors</th>\n",
       "      <th>genre</th>\n",
       "      <th>awards</th>\n",
       "      <th>runtime</th>\n",
       "      <th>type</th>\n",
       "      <th>poster</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt1711425</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>notalk</td>\n",
       "      <td>notalk</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380.0</td>\n",
       "      <td>42195766.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>tt1343727</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>ok-disagree</td>\n",
       "      <td>ok</td>\n",
       "      <td>PASS</td>\n",
       "      <td>45000000</td>\n",
       "      <td>13414714.0</td>\n",
       "      <td>40868994.0</td>\n",
       "      <td>2012PASS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt2024544</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>notalk-disagree</td>\n",
       "      <td>notalk</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035.0</td>\n",
       "      <td>158607035.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>...</td>\n",
       "      <td>Steve McQueen</td>\n",
       "      <td>08 Nov 2013</td>\n",
       "      <td>Chiwetel Ejiofor, Dwight Henry, Dickie Gravois...</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "      <td>Won 3 Oscars. Another 131 wins &amp; 137 nominations.</td>\n",
       "      <td>134 min</td>\n",
       "      <td>movie</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMjExMTEz...</td>\n",
       "      <td>143,446</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       imdb             title             test clean_test binary  \\\n",
       "0  2013  tt1711425     21 &amp; Over           notalk     notalk   FAIL   \n",
       "1  2012  tt1343727          Dredd 3D      ok-disagree         ok   PASS   \n",
       "2  2013  tt2024544  12 Years a Slave  notalk-disagree     notalk   FAIL   \n",
       "\n",
       "     budget    domgross     intgross      code  ...       director  \\\n",
       "0  13000000  25682380.0   42195766.0  2013FAIL  ...            NaN   \n",
       "1  45000000  13414714.0   40868994.0  2012PASS  ...            NaN   \n",
       "2  20000000  53107035.0  158607035.0  2013FAIL  ...  Steve McQueen   \n",
       "\n",
       "      released                                             actors  \\\n",
       "0          NaN                                                NaN   \n",
       "1          NaN                                                NaN   \n",
       "2  08 Nov 2013  Chiwetel Ejiofor, Dwight Henry, Dickie Gravois...   \n",
       "\n",
       "                       genre  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2  Biography, Drama, History   \n",
       "\n",
       "                                              awards  runtime   type  \\\n",
       "0                                                NaN      NaN    NaN   \n",
       "1                                                NaN      NaN    NaN   \n",
       "2  Won 3 Oscars. Another 131 wins & 137 nominations.  134 min  movie   \n",
       "\n",
       "                                              poster imdb_votes error  \n",
       "0                                                NaN        NaN   NaN  \n",
       "1                                                NaN        NaN   NaN  \n",
       "2  http://ia.media-imdb.com/images/M/MV5BMjExMTEz...    143,446   NaN  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data to a smaller number of columns: \"title\" and \"binary\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of movies that pass the Bechdel test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create the null distribution \n",
    "\n",
    "We need to create a null distribution, which is the distribution of statistics we would expect to get if the null hypothesis is true. \n",
    "\n",
    "**Question**: About what percent of the movies would we expect to pass the Bechdel test if the null distribution was true? \n",
    "\n",
    "**Answer**: \n",
    "\n",
    "Let's create simulated data that is consistent with this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate one proportion consistent with the null hypothesis\n",
    "\n",
    "# get the total number of movies in our dataset n\n",
    "\n",
    "\n",
    "\n",
    "# proportion consistent with the null hypothesis\n",
    "\n",
    "\n",
    "\n",
    "# one statistic consistent with null hypothesis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a null distribution \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate the p-value \n",
    "\n",
    "Calculate the proportion of points in the null distribution that are more extreme than the observed statistic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "\n",
    "# create a Boolean vector indicating whether each p-hat in the null distribution \n",
    "# was greater than the observed proportion that passed the Bechdel test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate the p-value \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Make a decision\n",
    "\n",
    "Since the p-value is very small (essentially zero) it is very unlikely that our statistic come from the null distribution. Thus we will reject the null hypothesis and conclude that less than 50% of movies pass the Bechdel test. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Another example: Hypothesis test for a single proportion - sinister lawyers\n",
    "\n",
    "10% of American popula on is left-handed. A study found that out of a random sample of 105 lawyers, 16 were left-handed. Use our 5 steps of hypothesis testing to assess whether the proportion of left-handed lawyers is greater than the proportion on found in the American population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: State the null and alternative hypotheses\n",
    "\n",
    "**In words** \n",
    "\n",
    "Null hypothesis: \n",
    "\n",
    "Alternative hypothesis: \n",
    "\n",
    "\n",
    "**In symbols**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the observed statistic\n",
    "\n",
    "Calculate the observed statistic and save it to the name `obs_stat`. \n",
    "\n",
    "What symbol should we use to denote this observed statistic? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create the null distribution \n",
    "\n",
    "To create the null distribution let's use the code we wrote to simulate the proportion of heads we get from flipping a coin *n* times. \n",
    "\n",
    "As we discusswed above, the code `flip_coins(n, prob_heads, return_prop)` simulates flipping a coin *n* times with a probability of getting heads given by the argument `prob_heads` (make sure you understand how this code works!). \n",
    "\n",
    "Use this code to simulate one statistic $\\hat{p}$ that is consistent with the null hypothesis below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate a null distribution, by using a for loop to create 10,000 statistics consistent with the null hypothesis. Store this null distribution in an object called `null_dist`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the null distribution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the null distribution as a histogram. Set the `bins` argument to 100 to create 100 bins in this histogram. \n",
    "\n",
    "Does the observed statistic you calculated in step 2 seem like it is likely to come from this null distribution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add a red vertical line at th evalue of the observed statistic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the p-value\n",
    "\n",
    "The p-value is the proportion of points in the null distribution that are more extreme than the observed statistic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Draw a conclusion\n",
    "\n",
    "Is there convincing evidence to reject the null hypothesis? \n",
    "\n",
    "Do you believe lawyers are more sinister than the general American public? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "<img src=\"https://github.com/emeyers/YData/blob/main/ClassMaterial/images/lawyer.jpg?raw=true\" alt=\"lawyer\" style=\"width: 200px;\"/>\n",
    "</center>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
