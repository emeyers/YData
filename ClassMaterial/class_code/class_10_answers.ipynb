{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 10: Intro to Data Visualization\n",
    "\n",
    "Plan for today:\n",
    "- Review pandas DataFrames\n",
    "- Discuss joining DataFrames\n",
    "- Discuss data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the class Jupyter setup\n",
    "\n",
    "If you have the *ydata123_2023e* environment set up correctly, you can get the class code using the code below (which presumably you've already done given that you are seeing this notebook).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(10)   # get class code    \n",
    "# YData.download.download_class_code(10, TRUE) # get the code with the answers \n",
    "\n",
    "YData.download.download_data(\"dow.csv\")\n",
    "YData.download.download_data(\"monthly_egg_prices.csv\")\n",
    "YData.download_data(\"US_Gasoline_Prices_Weekly.csv\")\n",
    "YData.download_data(\"The_Big_Game_Stats_2023.csv\")\n",
    "YData.download.download_data(\"nba_salaries_2015_16.csv\")\n",
    "YData.download.download_data(\"nba_position_names.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also similar functions to download the homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YData.download.download_homework(4)  # downloads the homework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should install polars and the YData packages by uncommenting and running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colabs, you should also uncomment and run the code below to mount the your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of processing DataFrames - warm-up problems\n",
    "\n",
    "To review manipulating pandas DataFrames, let's do a few warm-up exercises. \n",
    "\n",
    "In particular, let's look at information about the Super Bowl! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_bowl = pd.read_csv(\"The_Big_Game_Stats_2023.csv\")\n",
    "\n",
    "super_bowl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1:** To start, create a DataFrame called `super_simpler` that just has the following columns: \n",
    "- `Winner`: The name of the team that won the Super Bowl\n",
    "- `Winner_Pts`: The number of points the winning team scored\n",
    "- `Loser_Pts`: The number of points the losing team scored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just a subset of columns\n",
    "super_simpler = super_bowl[['Winner', 'Winner_Pts', 'Loser_Pts']].copy()\n",
    "\n",
    "super_simpler.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2:** Calcuate the mean score of teams that won and the mean score of team's that lost the Super Bowl. \n",
    "\n",
    "See if you can do this in a single line of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the mean number of points that super bowl winners and losers have scored? \n",
    "\n",
    "super_simpler[[\"Winner_Pts\", \"Loser_Pts\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3:** Now let's look at which teams have won the most super bowls. \n",
    "\n",
    "To do this create a DataFrame called `winner_counts` that has the number of times each team has won the Super Bowl, and sort this DataFrame in order so that teams that have won the most Super Bowls are on the top. \n",
    "\n",
    "\n",
    "Reminder: There are several ways to get multiple statistics by group. Perhaps the most useful way is to use the syntax:\n",
    "\n",
    "<pre>\n",
    "my_df.groupby(\"group_col_name\").agg(\n",
    "   new_col1 = ('col_name', 'statistic_name1'),\n",
    "   new_col2 = ('col_name', 'statistic_name2'),\n",
    "   new_col3 = ('col_name', 'statistic_name3')\n",
    ")\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_counts_alt = (super_simpler\n",
    " .groupby(\"Winner\")\n",
    " .agg(Num_Wins = (\"Winner_Pts\", \"count\"))\n",
    " .sort_values(\"Num_Wins\", ascending = False)\n",
    ")\n",
    "\n",
    "winner_counts_alt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way to solve the problem\n",
    "\n",
    "winner_counts = (super_simpler\n",
    " .groupby(\"Winner\")\n",
    " .count()\n",
    " .sort_values(\"Winner_Pts\", ascending = False)\n",
    ")\n",
    "\n",
    "\n",
    "winner_counts = (winner_counts\n",
    " .rename(columns = {\"Winner_Pts\": \"Number of Wins\"})[\"Number of Wins\"]\n",
    " .reset_index()\n",
    ")\n",
    "\n",
    "winner_counts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Joining\" DataFrames by Index\n",
    "\n",
    "To explore joining DataFrames, let's load the egg and wheat prices as DataFrames. \n",
    "\n",
    "We will also:\n",
    "- Rename the Price colomns to Egg Price and Wheat Price\n",
    "- Set the Index to be the date\n",
    "\n",
    "\n",
    "When two DataFrames have the same Index values, we can use the `.join()` method to join them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the egg and wheat prices as DataFrames\n",
    "egg_price_df = pd.read_csv(\"monthly_egg_prices.csv\", parse_dates=True, index_col= \"DATE\")\n",
    "egg_price_df = egg_price_df.rename(columns = {\"Price\":\"Egg Price\"})\n",
    "egg_price_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheat_price_df = pd.read_csv(\"monthly_wheat_prices.csv\", parse_dates=True, index_col= \"DATE\")\n",
    "wheat_price_df = wheat_price_df.rename(columns = {\"Price\":\"Wheat Price\"})\n",
    "wheat_price_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a left join by setting how = \"left\"\n",
    "# This will give same results as an outer join b/c the egg_price_df has all (and more) index values as the wheat_prices_df\n",
    "left_joined = egg_price_df.join(wheat_price_df, how = \"left\") \n",
    "left_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a right join by setting how = \"right\"  \n",
    "# This will give same results as an inner join b/c the egg_price_df has all (and more) index values as the wheat_prices_df\n",
    "right_joined = egg_price_df.join(wheat_price_df, how = \"right\") \n",
    "right_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Merging\" DataFrames by column values\n",
    "\n",
    "If we want to join by value in a column rather than by Index value we can use the `.merge()` method (which is very similar to the `.join()` method). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_price_df2 = egg_price_df.reset_index()\n",
    "egg_price_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheat_price_df2 = wheat_price_df.reset_index()\n",
    "\n",
    "wheat_price_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_joined2 = egg_price_df2.merge(wheat_price_df2, how = \"left\") \n",
    "left_joined2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging with different column names\n",
    "\n",
    "What if the columns we want to join on have different names, we can use the `left_on` and `right_on` arguments to specify which columns (i.e., keys) should be used to align the two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_price_df3 = egg_price_df2.rename(columns = {\"DATE\":\"Egg DATE\"})\n",
    "wheat_price_df3 = wheat_price_df2.rename(columns = {\"DATE\": \"Wheat DATE\"})\n",
    "\n",
    "wheat_price_df3.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_price_df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_joined3 = egg_price_df3.merge(wheat_price_df3, how = \"left\", left_on = \"Egg DATE\", right_on = \"Wheat DATE\") \n",
    "left_joined3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Spelling out NBA position names\n",
    "\n",
    "As you will recall, our NBA salaries DataFrame had the different positions listed as abbreviations such as \"C\" and \"PG\". \n",
    "\n",
    "Often it is hard to tell what these abbreviations (or codes) mean, so a common use of joining is to join on to a table a list of longer names that give more meaning to abbreviations. \n",
    "\n",
    "Below we load our `nba_salaries` DataFrame along with a `nba_positions` DataFrame which has information about how each position abbreviation maps on to the position's full name.\n",
    "\n",
    "Let's merge these DataFrames together so that our `nba_salaries` DataFrame has the full position names!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_salaries = pd.read_csv(\"nba_salaries_2015_16.csv\")\n",
    "\n",
    "nba_salaries.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_positions = pd.read_csv(\"nba_position_names.csv\")\n",
    "nba_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the DataFrames together so each player's position is the full position name\n",
    "\n",
    "nba_improved = nba_salaries.merge(nba_positions, left_on = \"POSITION\", right_on = \"Position Abbreviation\")\n",
    "\n",
    "nba_improved.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns using the .drop(colums = )  method\n",
    "nba_improved.drop(columns = [\"POSITION\", \"Position Abbreviation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pandas](https://image.goat.com/transform/v1/attachments/product_template_additional_pictures/images/071/445/310/original/719082_01.jpg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization!\n",
    "\n",
    "Let's go through different ways to visualize data. To do this let's look again and Egg and Gas prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_prices = pd.read_csv(\"monthly_egg_prices.csv\", parse_dates = [0])\n",
    "gas_prices = pd.read_csv(\"US_Gasoline_Prices_Weekly.csv\", parse_dates = [0])\n",
    "\n",
    "print(egg_prices.head(3))\n",
    "\n",
    "gas_prices.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, let's get a little more practice joining DataFrames by joining the egg and gas prices together into a single DataFrame. \n",
    "\n",
    "Let's do an inner join to only keep the dates where we have prices for both eggs and gas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the egg and gas prices\n",
    "prices = egg_prices.merge(gas_prices, how = \"inner\", left_on = \"DATE\",\n",
    "                          right_on = \"Week\")\n",
    "\n",
    "prices.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also clean up our prices data by only keeping the columns we need, and renaming them to more meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the columns we need\n",
    "prices = prices[[\"Week\", \"Price\", \"DollarsPerGallon\"]]\n",
    "\n",
    "# rename the columns to have more meaningful names\n",
    "prices = prices.rename(columns = {\"Price\": \"Eggs\", \"DollarsPerGallon\":\"Gas\"})\n",
    "\n",
    "prices.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start visualizing the data!\n",
    "\n",
    "Let's start by creating line plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a line plot of egg prices, and also include a circle marker at each point \n",
    "plt.plot(prices[\"Eggs\"], \"-o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have the x-axis be the actual dates\n",
    "plt.plot(prices[\"Week\"], prices[\"Eggs\"], \"-o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is [wrong](https://xkcd.com/833/) with these plots???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this better!\n",
    "plt.plot(prices[\"Week\"], prices[\"Eggs\"], \"-o\");\n",
    "plt.ylabel(\"Price ($)\");\n",
    "plt.xlabel(\"Date\");\n",
    "plt.title(\"Egg prices over time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare egg and gas prices on the same plot\n",
    "\n",
    "plt.plot(prices[\"Week\"], prices[\"Eggs\"], \"-o\", label = \"Eggs\");\n",
    "plt.plot(prices[\"Week\"], prices[\"Gas\"], \"-o\", label = \"Gas\");\n",
    "\n",
    "plt.ylabel(\"Price ($)\");\n",
    "plt.xlabel(\"Date\");\n",
    "plt.title(\"Egg prices over time\");\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side note: Are there any weeks where Eggs cost more than Gas? \n",
    "\n",
    "# Can you use pandas to show this?  \n",
    "\n",
    "prices2 = prices.copy()\n",
    "\n",
    "prices2[\"Price Diff\"] = prices2[\"Gas\"] - prices2[\"Eggs\"]\n",
    "\n",
    "prices2.sort_values(\"Price Diff\").head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms \n",
    "\n",
    "We can create histograms using the `plt.hist()` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prices[\"Gas\"], edgecolor = \"black\", bins = 20, alpha = .5);\n",
    "plt.xlabel(\"Price ($)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Weekly US average gas prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prices[\"Gas\"], edgecolor = \"black\", bins = 20, alpha = .5, label = \"Gas\");\n",
    "plt.hist(prices[\"Eggs\"], edgecolor = \"black\", bins = 20, alpha = .5, label = \"Egg\");\n",
    "plt.xlabel(\"Price ($)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will continue more with visualizing data next week...\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/science_valentine.png\">\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ydata123_2023e] *",
   "language": "python",
   "name": "conda-env-ydata123_2023e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
