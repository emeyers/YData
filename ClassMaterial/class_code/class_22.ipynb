{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 22: Hypothesis tests continued\n",
    "\n",
    "Plan for today:\n",
    "- Hypothesis tests assessing causality  \n",
    "- Confidence intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the class Jupyter setup\n",
    "\n",
    "If you have the *ydata123_2023e* environment set up correctly, you can get the class code using the code below (which presumably you've already done given that you are seeing this notebook).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file `bta.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n",
      "The file `movies.csv` already exists.\n",
      "If you would like to download a new copy of the file, please rename the existing copy of the file.\n"
     ]
    }
   ],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(22)   # get class code    \n",
    "# YData.download.download_class_code(22, TRUE) # get the code with the answers \n",
    "\n",
    "YData.download_data(\"bta.csv\")\n",
    "YData.download_data(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also similar functions to download the homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YData.download.download_homework(8)  # downloads the homework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should install the YData packages by uncommenting and running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/emeyers/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colabs, you should also uncomment and run the code below to mount the your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis tests\n",
    "\n",
    "In hypothesis testing, we start with a claim about a population parameter (e.g., µ = 4.2, or π = 0.25).\n",
    "\n",
    "This claim implies we should get a certain distribution of statistics, called \"The null distribution\". \n",
    "\n",
    "If our observed statistic is highly unlikely to come from the null distribution, we reject the claim. \n",
    "\n",
    "We can break down the process of running a hypothesis test into 5 steps. \n",
    "\n",
    "1. State the null and alternative hypothesis\n",
    "2. Calculate the observed statistic of interest\n",
    "3. Create the null distribution \n",
    "4. Calculate the p-value \n",
    "5. Make a decision\n",
    "\n",
    "Let's run through these steps now!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hypothesis test assessing causal relationships\n",
    "\n",
    "To get at causality we can run a Randomized Controlled Trial (RTC), where have of the participants are randomly assigned to a \"treatment group\" that receives an intervention and the other half of participants are put in a \"control group\" which receives a placebo. If the treatment group shows a an improvement over the control group that is larger than what is expected by chance, this indicates that the treatment **causes** an improvement. \n",
    "\n",
    "\n",
    "#### Botulinum Toxin A (BTA) as a treatment to chronic back pain\n",
    "\n",
    "A study by Foster et al (2001) examined whether Botulinum Toxin A (BTA) was an effective treatment for chronic back pain.\n",
    "\n",
    "In the study, participants were randomly assigned to be in a treatment or control group: \n",
    "- 15 in the treatment group\n",
    "- 16 in the control group (normal saline)\n",
    "\n",
    "Trials were run double-blind (neither doctors nor patients knew which group they were in)\n",
    "\n",
    "Result from the study were coded as:\n",
    "  - 1 indicates pain relief\n",
    "  - 0 indicates lack of pain relief \n",
    "\n",
    "\n",
    "Let's run a hypothesis test to see if BTA causes a decrease in back pain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: State the null and alternative hypotheses\n",
    "\n",
    "\n",
    "$H_0$: $\\pi_{treat} =  \\pi_{control}$   or    $H_0$: $\\pi_{treat} -  \\pi_{control} = 0$ \n",
    "\n",
    "$H_A$: $\\pi_{control} < \\pi_{treat}$    or    $H_0$: $\\pi_{treat} -  \\pi_{control} < 0$ \n",
    "\n",
    "\n",
    "\n",
    "Where $\\pi_{treat}$ and $\\pi_{control}$ and the population proportions of people who experienced back pain relief after receiving the BTA or control respectively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the observed statistic\n",
    "\n",
    "The code below loads the data from the study. We can use the difference in proportions  $\\hat{p}_{treat} - \\hat{p}_{control}$  as our observed statistic. \n",
    "\n",
    "Let's calculate the observe statistic and save it to the name `obs_stat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Group  Result\n",
       "10    Control     0.0\n",
       "12    Control     0.0\n",
       "6     Control     0.0\n",
       "23  Treatment     1.0\n",
       "1     Control     1.0\n",
       "29  Treatment     0.0\n",
       "30  Treatment     0.0\n",
       "4     Control     0.0\n",
       "5     Control     0.0\n",
       "19  Treatment     1.0\n",
       "3     Control     0.0\n",
       "28  Treatment     0.0\n",
       "20  Treatment     1.0\n",
       "0     Control     1.0\n",
       "2     Control     0.0\n",
       "16  Treatment     1.0\n",
       "24  Treatment     1.0\n",
       "14    Control     0.0\n",
       "15    Control     0.0\n",
       "17  Treatment     1.0\n",
       "8     Control     0.0\n",
       "22  Treatment     1.0\n",
       "27  Treatment     0.0\n",
       "26  Treatment     0.0\n",
       "18  Treatment     1.0\n",
       "21  Treatment     1.0\n",
       "11    Control     0.0\n",
       "13    Control     0.0\n",
       "7     Control     0.0\n",
       "25  Treatment     0.0\n",
       "9     Control     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bta = pd.read_csv('bta.csv')\n",
    "bta.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame with the proportion of people in the treatment and control groups that have pain relief \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the observed statistic from our DataFrame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a function to make it easy to get statistic values\n",
    "\n",
    "def get_prop_diff(bta_data):\n",
    "    \n",
    "    ...\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create the null distribution \n",
    "\n",
    "To create the null distribution, we need to create statistics consistent with the null hypothesis. \n",
    "\n",
    "In this example, if the null hypothesis was true, then there would be no difference between the treatment and control group. Thus, under the null hypothesis, we can shuffle the group labels and get equally valid statistics. \n",
    "\n",
    "Let's create one statistic consistent with the null distribution to understand the process. We can then repeat this 10,000 times to get a full null distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one statistic consistent with the null distribution \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create a full null distribution \n",
    "\n",
    "null_dist = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution \n",
    "\n",
    "\n",
    "\n",
    "# put a line at the observed statistic value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the p-value\n",
    "\n",
    "The p-value is the proportion of points in the null distribution that are more extreme than the observed statistic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Draw a conclusion\n",
    "\n",
    "Since the p-value is less than the typical significance level of 0.05, we can reject the null hypothesis and conclude that BTA does **cause** pain relief at a higher rate than the placebo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using hypothesis tests to generate confidence intervals\n",
    "\n",
    "There are several methods we that can be used to calculate confidence intervals, including using a computational method called the \"bootstrap\" and using \"parametric methods\" that involve using probability distributions. If you take a traditional introductory statistics class you will learn some of these methods.\n",
    "\n",
    "Below we use a less conventional method to calculate confidence intervals by looking at all parameters values that a hypothesis test fails to reject (at the p-value < 0.05 level). As you will see, the method gives similar results to other methods, although it requires a bit more computation time.\n",
    "\n",
    "As an example, let's create a confidence interval for the population proportion of movies $\\pi$ that pass the Bechdel test. As is the case for all confidence intervals, this confidence interval gives a range of plausible values that likely contains the true population proportion $\\pi$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5039018952062431"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To start, let's use a function that generates a statistic p-hat \n",
    "# that is consistent with a particular population parameter value pi\n",
    "\n",
    "def generate_prop_bechdel(n, null_prop):\n",
    "    \n",
    "    random_sample = np.random.rand(n) <= null_prop\n",
    "    return np.mean(random_sample)\n",
    "\n",
    "generate_prop_bechdel(1794, .5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below calculates a p-value for the Bechdel data based on a particular pi value that is specified in a null hypothesis.\n",
    "# (i.e., it is a function that encapsulates the hypothesis test you ran in class 20).\n",
    "\n",
    "\n",
    "def get_Bechdel_pvalue(null_hypothesis_pi, plot_null_dist = False):\n",
    "    \n",
    "    \n",
    "    # The observed p-hat value\n",
    "    prop_passed = 803/1794\n",
    "    \n",
    "    \n",
    "    # Generate the null distribution \n",
    "    null_dist = []\n",
    "    \n",
    "    for i in range(10000):    \n",
    "        null_dist.append(generate_prop_bechdel(1794, null_hypothesis_pi))\n",
    "    \n",
    "    \n",
    "    # Calculate a \"two-tailed\" p-value which is the proportion of statistcs more extreme than the observed statistic\n",
    "    \n",
    "    statistic_deviation = np.abs(null_hypothesis_pi - prop_passed)\n",
    "    \n",
    "    pval_left = np.mean(np.array(null_dist) <= null_hypothesis_pi - statistic_deviation)\n",
    "    pval_right = np.mean(np.array(null_dist) >= null_hypothesis_pi + statistic_deviation)\n",
    "    \n",
    "    p_value = pval_left + pval_right\n",
    "\n",
    "    \n",
    "    # plot the null distribution and lines indicating values more extreme than the observed statistic \n",
    "    if plot_null_dist:\n",
    "        \n",
    "        plt.hist(null_dist, edgecolor = \"black\", bins = 30);\n",
    "        plt.axvline(null_hypothesis_pi - statistic_deviation, color = \"red\");\n",
    "        plt.axvline(null_hypothesis_pi + statistic_deviation, color = \"red\");\n",
    "        plt.axvline(null_hypothesis_pi, color = \"yellow\");\n",
    "\n",
    "        \n",
    "        plt.title(\"Pi-null is: \" + str(null_hypothesis_pi) + \"      \"  +\n",
    "                  \"p-value is: \" + str(round(p_value, 5)))\n",
    "      \n",
    "    # return the p-value\n",
    "    return p_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function with the value H0: pi = .5  (as we did in class 20)\n",
    "\n",
    "\n",
    "\n",
    "# test the function with the value H0: pi = .45\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a range range of H0: pi = x  values\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get the p-value for a range of H0: pi = x  values\n",
    "\n",
    "\n",
    "pvalues = []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the p-values \n",
    "# convention calls a p-value < 0.05 is \"statistically significant\" indicating a pi imcompatible with the null hypothesis\n",
    "# our confidence interval is all pi values that are not statistically significant (i.e., pi values that are consistent with particular H0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all plausible Pi values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the CI as the max and min plausible pi values \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the statsmodels package to compute a confidence interval for a proportion\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-ydata123_2023e]",
   "language": "python",
   "name": "conda-env-anaconda3-ydata123_2023e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
